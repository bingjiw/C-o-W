# encoding:utf-8

import time

import openai
import openai.error
import requests

from bot.bot import Bot
from bot.chatgpt.chat_gpt_session import ChatGPTSession
from bot.openai.open_ai_image import OpenAIImage
from bot.session_manager import SessionManager
from bridge.context import ContextType
from bridge.reply import Reply, ReplyType
from common.log import logger
from common.token_bucket import TokenBucket
from config import conf, load_config


# OpenAIå¯¹è¯æ¨¡å‹API (å¯ç”¨)
class ChatGPTBot(Bot, OpenAIImage):
    def __init__(self, Which_LLM_To_Create="BasicLLM", session_manager=None):
        super().__init__()
        
        #å­˜ä¸€ä»½api_keyï¼Œä»¥ä¾¿åœ¨reply_textï¼ˆä¸ä¼ å…¥api_keyæ—¶ï¼‰ä¸­ä½¿ç”¨
        self.the_API_KEY_gave_me_when_I_born = conf().get(Which_LLM_To_Create)["open_ai_api_key"]
        # set the default api_key
        openai.api_key = self.the_API_KEY_gave_me_when_I_born

        #å­˜ä¸€ä»½api_base
        self.the_API_BASE_gave_me_when_I_born = conf().get(Which_LLM_To_Create)["open_ai_api_base"]
        if self.the_API_BASE_gave_me_when_I_born:
            openai.api_base = self.the_API_BASE_gave_me_when_I_born

        proxy = conf().get("proxy")
        if proxy:
            openai.proxy = proxy
        if conf().get("rate_limit_chatgpt"):
            self.tb4chatgpt = TokenBucket(conf().get("rate_limit_chatgpt", 20))

        # ç‚³æ³¨ï¼š
        #ä»¥ä¸Šçš„ openai.api_key, openai.api_base, openai.proxy, éƒ½æ˜¯åº“çš„å…¨å±€å˜é‡ï¼Œæ— æ³•ç»™æ¯ä¸ªbotå®ä¾‹è®¾ç½®ä¸åŒçš„å€¼
        #åªæœ‰ä¸‹æ–¹çš„ model å¯ä»¥ç»™æ¯ä¸ªbotå®ä¾‹è®¾ç½®ä¸åŒçš„å€¼
        # SessionManageråŠå…¶å­ç±»ChatGPTSession ä¸­çš„modelä»…ç”¨äºè®¡ç®—ä»¤ç‰Œæ•°é‡ã€‚
        
        #self.sessions = SessionManager(ChatGPTSession, model=conf().get(Which_LLM_To_Create)["model"] or "gpt-3.5-turbo")
        # ç‚³ï¼šåŸå¦‚ä¸Šï¼Œç°æ”¹ä¸ºBasicLLMä¸FreeLLMè¿™2ä¸ªBOTç”¨å…±äº«ä¸€ä¸ªsessions     Use the provided session_manager or create a new one
        self.sessions = session_manager or SessionManager(ChatGPTSession, model=conf().get(Which_LLM_To_Create)["model"] or "gpt-3.5-turbo")
        
        self.args = {
            "model": conf().get(Which_LLM_To_Create)["model"] or "gpt-3.5-turbo",  # å¯¹è¯æ¨¡å‹çš„åç§°
            "temperature": conf().get("temperature", 0.9),  # å€¼åœ¨[0,1]ä¹‹é—´ï¼Œè¶Šå¤§è¡¨ç¤ºå›å¤è¶Šå…·æœ‰ä¸ç¡®å®šæ€§
            # "max_tokens":4096,  # å›å¤æœ€å¤§çš„å­—ç¬¦æ•°
            "top_p": conf().get("top_p", 1),
            "frequency_penalty": conf().get("frequency_penalty", 0.0),  # [-2,2]ä¹‹é—´ï¼Œè¯¥å€¼è¶Šå¤§åˆ™æ›´å€¾å‘äºäº§ç”Ÿä¸åŒçš„å†…å®¹
            "presence_penalty": conf().get("presence_penalty", 0.0),  # [-2,2]ä¹‹é—´ï¼Œè¯¥å€¼è¶Šå¤§åˆ™æ›´å€¾å‘äºäº§ç”Ÿä¸åŒçš„å†…å®¹
            "request_timeout": conf().get("request_timeout", None),  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œopenaiæ¥å£é»˜è®¤è®¾ç½®ä¸º600ï¼Œå¯¹äºéš¾é—®é¢˜ä¸€èˆ¬éœ€è¦è¾ƒé•¿æ—¶é—´
            "timeout": conf().get("request_timeout", None),  # é‡è¯•è¶…æ—¶æ—¶é—´ï¼Œåœ¨è¿™ä¸ªæ—¶é—´å†…ï¼Œå°†ä¼šè‡ªåŠ¨é‡è¯•
        }

    def reply(self, query, context=None):
        # acquire reply content
        if context.type == ContextType.TEXT or (context.TextizedText is not None) :
            logger.info("[CHATGPT] query={}".format(query))

            session_id = context["session_id"]
            reply = None
            clear_memory_commands = conf().get("clear_memory_commands", ["#æ¸…é™¤è®°å¿†"])
            if query in clear_memory_commands:
                self.sessions.clear_session(session_id)
                reply = Reply(ReplyType.INFO, "è®°å¿†å·²æ¸…é™¤")
            elif query == "#æ¸…é™¤æ‰€æœ‰":
                self.sessions.clear_all_session()
                reply = Reply(ReplyType.INFO, "æ‰€æœ‰äººè®°å¿†å·²æ¸…é™¤")
            elif query == "#æ›´æ–°é…ç½®":
                load_config()
                reply = Reply(ReplyType.INFO, "é…ç½®å·²æ›´æ–°")
            if reply:
                return reply
            session = self.sessions.session_query(query, session_id)
            logger.debug("[CHATGPT] session query={}".format(session.messages))

            api_key = context.get("openai_api_key")
            model = context.get("gpt_model")
            new_args = None
            if model:
                new_args = self.args.copy()
                new_args["model"] = model
            # if context.get('stream'):
            #     # reply in stream
            #     return self.reply_text_stream(query, new_query, session_id)

            reply_content = self.reply_text(session, api_key, args=new_args)
            logger.debug(
                "[CHATGPT] new_query={}, session_id={}, reply_cont={}, completion_tokens={}".format(
                    session.messages,
                    session_id,
                    reply_content["content"],
                    reply_content["completion_tokens"],
                )
            )
            if reply_content["completion_tokens"] == 0 and len(reply_content["content"]) > 0:
                reply = Reply(ReplyType.ERROR, reply_content["content"])
            elif reply_content["completion_tokens"] > 0:
                self.sessions.session_reply(reply_content["content"], session_id, reply_content["total_tokens"])
                reply = Reply(ReplyType.TEXT, reply_content["content"])
            else:
                reply = Reply(ReplyType.ERROR, reply_content["content"])
                logger.debug("[CHATGPT] reply {} used 0 tokens.".format(reply_content))
            return reply

        elif context.type == ContextType.IMAGE_CREATE:
            ok, retstring = self.create_img(query, 0)
            reply = None
            if ok:
                reply = Reply(ReplyType.IMAGE_URL, retstring)
            else:
                reply = Reply(ReplyType.ERROR, retstring)
            return reply
        else:
            reply = Reply(ReplyType.ERROR, "Botä¸æ”¯æŒå¤„ç†{}ç±»å‹çš„æ¶ˆæ¯".format(context.type))
            return reply



    def reply_text(self, session: ChatGPTSession, api_key=None, args=None, retry_count=0) -> dict:
        """
        call openai's ChatCompletion to get the answer
        :param session: a conversation session
        :param session_id: session id
        :param retry_count: retry count
        :return: {}
        """
        try:
            if conf().get("rate_limit_chatgpt") and not self.tb4chatgpt.get_token():
                raise openai.error.RateLimitError("RateLimitError: rate limit exceeded")

            # ç‚³æ³¨ï¼šåŸæ­¤å¥èƒ¡è¯´å…«é“ï¼šå®³äººï¼šif api_key == None, the default openai.api_key will be used

            # ç‚³ï¼šplugin_summary\main.py ç›´æ¥è°ƒç”¨reply_textä¼šå‡ºé”™ï¼ˆå› api_key=Noneï¼‰ï¼Œå› ä¸ºæ²¡æœ‰ä¼ å…¥api_key
            #    æ‰€ä»¥åœ¨æ­¤å¯¹æ²¡æœ‰è½¬å…¥api_keyçš„æƒ…å†µè¿›è¡Œå¤„ç†
            if api_key == None:
                api_key = self.the_API_KEY_gave_me_when_I_born

            if args is None:
                args = self.args

            # ç‚³ï¼šæ‰“å°å‡ºçœŸæ­£å»è°ƒLLMæ—¶ï¼Œè°ƒç”¨å‘å‡ºçš„å‚æ•°
            import json
            logger.debug(f"ChatGPTBotçœŸæ­£å»è°ƒLLMæ—¶ï¼Œè°ƒç”¨å‘å‡ºå“ªäº›ï¼š\napi_key={api_key}\nmessages={session.messages}\nargs={json.dumps(args, ensure_ascii=False, indent=2)}")

            # ç‚³ï¼šè¿™å¥æ˜¯ çœŸæ­£å»è°ƒ LLM    
            response = openai.ChatCompletion.create(api_key=api_key, messages=session.messages, **args)
            # logger.debug("[CHATGPT] response={}".format(response))
            # logger.info("[ChatGPT] reply={}, total_tokens={}".format(response.choices[0]['message']['content'], response["usage"]["total_tokens"]))
            


            #VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV
            #å¦‚æœç­”æ¡ˆä¸­å«æœ‰â€œ> **end-searching**â€ï¼Œè¯´æ˜æ˜¯è°ƒgpt-4oäº§ç”Ÿçš„å•°å—¦ç­”æ¡ˆï¼Œåˆ™è¦è¿›è¡Œä¿®å‰ª
            #ç‚³ï¼šæ‹¿å‡ºå›å¤çš„å†…å®¹ï¼Œä»¥å»æ‰ï¼šå¼€å¤´çš„å‡ è¡Œå¼•å¯¼ä¿¡æ¯å’Œå‚è€ƒçš„ç½‘é¡µé“¾æ¥ï¼Œæ ·ä¾‹å¦‚ä¸‹
            # > search("Trump shooting latest news July 18 2024")
            # > mclick(["1", "3", "5", "6", "8"])
            # > search error
            #
            # > mclick(["2", "10", "12", "13", "17"])
            # > **end-searching**
            #
            # æ˜¨å¤©ï¼Œç‰¹æœ—æ™®æ€»ç»Ÿåœ¨å®¾å¤•æ³•å°¼äºšå·çš„é›†ä¼šä¸Šé­é‡æªå‡»ã€‚å«Œç–‘äººæ‰˜é©¬æ–¯Â·é©¬ä¿®Â·å…‹é²å…‹æ–¯ä»å±‹é¡¶å‘èˆå°å¼€æªã€‚ç‰¹æœ—æ™®å—è½»ä¼¤ï¼Œä½†æƒ…å†µç¨³å®šã€‚ä¸€åæ¶ˆé˜²å‘˜åœ¨äº‹ä»¶ä¸­é‡éš¾ï¼Œå¦æœ‰ä¸¤äººå—ä¼¤ã€‚ç¾å›½ç‰¹å‹¤å±€è¿…é€Ÿè¡ŒåŠ¨ï¼Œå«Œç–‘äººå·²è¢«æ‹˜ç•™ã€‚ç‰¹æœ—æ™®ç§°æ­¤äº‹ä»¶ä¸ºâ€œç¥çš„ä¿ä½‘â€ï¼Œå¹¶å‘¼åå…¨å›½å›¢ç»“[Trump shooting latest updates](https://ny1.com/nyc/all-boroughs/news/2024/07/14/trump-shooting-live-updates-assassination-attempt-rally)ã€8â€ sourceã€‘ã€‚
            # --------åˆä¸€ä¾‹ï¼Œå¦‚ä¸‹--------
            # > search("astaxanthin half-life 2024")
            # > search("current half-life of astaxanthin 2024")
            # > mclick(["1", "11", "6", "14", "9"])
            # > mclick([0, 1, 5, 6, 10])
            # > **end-searching**

            # æ ¹æ®æœ€æ–°èµ„æ–™ï¼Œè™¾é’ç´ çš„
            # > **end-searching**

            # åŠ
            # > **end-searching**

            # è¡°æœŸå¤§çº¦ä¸º16å°æ—¶ã€‚è¿™æ„å‘³ç€åœ¨æœç”¨åï¼Œå¤§çº¦16å°æ—¶åä½“å†…çš„è™¾é’ç´ æµ“åº¦ä¼šå‡å°‘ä¸€åŠ[New study uncovers astaxanthin's anti-inflammatory potential against lipopolysaccharide-induced inflammation](https://medicalxpress.com/news/2024-05-uncovers-astaxanthin-anti-inflammatory-potential.html)[New Astaxanthin Formulation Said to Provide Ideal, More-Absorbable Dose](https://www.nutritionaloutlook.com/view/new-astaxanthin-formulation-said-provide-ideal-more-absorbable-dose)[Astaxanthin - Wikipedia](https://en.wikipedia.org/wiki/Astaxanthin)ã€‚è™¾é’ç´ ä½œä¸ºğŸŒä¸€ç§ğŸŒè„‚ğŸŒæœ€æ–°çš„ç ”ç©¶è¡¨æ˜ï¼Œè™¾é’æº¶ç´ çš„æ€§åŠç‰©è¡°è´¨æœŸå¤§ï¼Œå…¶çº¦ä¸ºåœ¨16åˆ°ä½“20å°æ—¶å†…å¯ä»¥ã€‚è¿™ä¸€æŒç»­æ•°æ®æ›´è¡¨é•¿æ˜ï¼Œæ—¶é—´è™¾é’ï¼Œç´ åœ¨é€šå¸¸ä½“åœ¨å†…èƒ½å¤Ÿè¡€ç»´æŒæ¸…ç›¸ä¸­å¯¹ç¨³å®šçš„å¯æµ“åº¦æ£€æµ‹ï¼Œåˆ°æ”¯æŒå…¶çš„æŠ—æ°§æ—¶é—´åŒ–å’Œé•¿æŠ—ç‚è¾¾åŠŸèƒ½72å°æ—¶[Molecules | Free Full-Text | The Role of Astaxanthin as a Nutraceutical in Health and Age-Related Conditions](https://www.mdpi.com/1420-3049/27/21/7167)[New study uncovers astaxanthin's anti-inflammatory potential against lipopolysaccharide-induced inflammation](https://medicalxpress.com/news/2024-05-uncovers-astaxanthin-anti-inflammatory-potential.html)ã€7â€ sourceã€‘[Evidence-based Analysis on Supplements & Nutrition | Examine](https://examine.com/supplements/astaxanthin/research/)ã€‚

            # ã€‚å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿ç»§ç»­æé—®ã€‚

            strResponseText = response.choices[0]["message"]["content"]
            if "> **end-searching**" in strResponseText:
                import re
                # åˆ é™¤ä»¥ `>` åé¢è·Ÿéšç©ºæ ¼å’Œå°å†™å­—æ¯å¼€å¤´çš„æ¯ä¸€è¡Œ
                cleaned_text = re.sub(r'^> [a-z].*$', '', strResponseText, flags=re.MULTILINE)
                # åˆ é™¤å¸¦æœ‰ URL çš„æ–¹æ‹¬å·éƒ¨åˆ†
                cleaned_text = re.sub(r'\[.*?\]\((?:http|https)://\S+\)', '', cleaned_text)
                # åˆ é™¤ç±»ä¼¼ ã€7â€ sourceã€‘ çš„å­—ä¸²
                cleaned_text = re.sub(r'ã€\d+â€ sourceã€‘', '', cleaned_text)
                #åˆ é™¤  > **end-searching**
                cleaned_text = cleaned_text.replace("> **end-searching**\n","")
                # åˆ é™¤æ–‡ç« å¼€å¤´å¤šä½™çš„æ¢è¡Œä¸ç©ºæ ¼
                cleaned_text = re.sub(r'^\s*', '', cleaned_text, flags=re.MULTILINE)
                #åŠ ğŸŒï¼Œè¡¨ç¤º æ˜¯ gpt-4oæœç´¢å¾—æ¥çš„ï¼Œæ•…æ„ä¸LINKAIçš„åœ°çƒä¸åŒæ ·å­
                cleaned_text = "ğŸŒ"+cleaned_text
                logger.debug("åŸå§‹å•°å”†ç­”æ¡ˆï¼š\n{}\nğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªšğŸªš\nä¿®å‰ªåçš„å¹²å‡€ç­”æ¡ˆï¼š\n{}".format(strResponseText, cleaned_text))
            else:
                cleaned_text = strResponseText

            return {
                "total_tokens": response["usage"]["total_tokens"],
                "completion_tokens": response["usage"]["completion_tokens"],
                "content": cleaned_text,
            }
        except Exception as e:
            need_retry = retry_count < 2

            #ç‚³ã€Šã€Šã€Šã€Š é’ˆå¯¹ç”¨æˆ·é—®äº† **ç›¸å…³çš„æ•æ„Ÿé—®é¢˜ å¼•å‘çš„å¼‚å¸¸ çš„å¤„ç†
            #ç‚³ã€Šã€Šã€Šã€Š Input data may contain inappropriate content.
            exception_message = str(e)  # Convert the exception to a string
            if "data may contain inappropriate content" in exception_message:
                textToReplyUser = exception_message + conf().get("warning_reply_for_inappropriate_content")

                result = {"completion_tokens": 0, "content": textToReplyUser}
            else:
                result = {"completion_tokens": 0, "content": "æˆ‘ç°åœ¨æœ‰ç‚¹ç´¯äº†ï¼Œç­‰ä¼šå†æ¥å§"}
            
            if isinstance(e, openai.error.RateLimitError):
                logger.warn("[CHATGPT] RateLimitError: {}".format(e))
                result["content"] = f"æˆ‘ç°åœ¨å¾ˆå¿™ï¼Œå·²æ¥è¿‘å›ç­”é—®é¢˜çš„æé™èƒ½åŠ›ï¼ˆæ¯åˆ†é’Ÿ{conf().get('rate_limit_chatgpt')}ä¸ªï¼‰ã€‚\n\nå†ç­‰æˆ‘2åˆ†é’Ÿ,ä¸€æœ‰ç©ºå°±å›ç­”ä½ \n\n2åˆ†é’Ÿåå†é—®æˆ‘\n\nè‹¥å‡ æ¬¡éƒ½æ²¡ç­”ï¼Œè¯·è®©æŠ€æœ¯å‘˜ bingjiw å¢åŠ æˆ‘çš„èƒ½åŠ›"
                if need_retry:
                    time.sleep(20)
            elif isinstance(e, openai.error.Timeout):
                logger.warn("[CHATGPT] Timeout: {}".format(e))
                result["content"] = "æˆ‘æ²¡æœ‰æ”¶åˆ°ä½ çš„æ¶ˆæ¯"
                if need_retry:
                    time.sleep(5)
            elif isinstance(e, openai.error.APIError):
                logger.warn("[CHATGPT] Bad Gateway: {}".format(e))
                result["content"] = "ç½‘ç»œæ•…éšœï¼Œè¯·ç¨å€™å†é—®ã€‚å¦‚æœå‡ æ¬¡éƒ½ä¸è¡Œï¼Œè¯·è”ç³»æŠ€æœ¯å‘˜ bingjiw"
                if need_retry:
                    time.sleep(10)
            elif isinstance(e, openai.error.APIConnectionError):
                logger.warn("[CHATGPT] APIConnectionError: {}".format(e))
                result["content"] = "æˆ‘è¿æ¥ä¸åˆ°ä½ çš„ç½‘ç»œ"
                if need_retry:
                    time.sleep(5)
            else:
                logger.exception("[CHATGPT] Exception: {}".format(e))
                need_retry = False
                self.sessions.clear_session(session.session_id)

            if need_retry:
                logger.warn("[CHATGPT] ç¬¬{}æ¬¡é‡è¯•".format(retry_count + 1))
                return self.reply_text(session, api_key, args, retry_count + 1)
            else:
                return result


class AzureChatGPTBot(ChatGPTBot):
    def __init__(self):
        super().__init__()
        openai.api_type = "azure"
        openai.api_version = conf().get("azure_api_version", "2023-06-01-preview")
        self.args["deployment_id"] = conf().get("azure_deployment_id")

    def create_img(self, query, retry_count=0, api_key=None):
        text_to_image_model = conf().get("text_to_image")
        if text_to_image_model == "dall-e-2":
            api_version = "2023-06-01-preview"
            endpoint = conf().get("azure_openai_dalle_api_base","open_ai_api_base")
            # æ£€æŸ¥endpointæ˜¯å¦ä»¥/ç»“å°¾
            if not endpoint.endswith("/"):
                endpoint = endpoint + "/"
            url = "{}openai/images/generations:submit?api-version={}".format(endpoint, api_version)
            api_key = conf().get("azure_openai_dalle_api_key","open_ai_api_key")
            headers = {"api-key": api_key, "Content-Type": "application/json"}
            try:
                body = {"prompt": query, "size": conf().get("image_create_size", "256x256"),"n": 1}
                submission = requests.post(url, headers=headers, json=body)
                operation_location = submission.headers['operation-location']
                status = ""
                while (status != "succeeded"):
                    if retry_count > 3:
                        return False, "å›¾ç‰‡ç”Ÿæˆå¤±è´¥"
                    response = requests.get(operation_location, headers=headers)
                    status = response.json()['status']
                    retry_count += 1
                image_url = response.json()['result']['data'][0]['url']
                return True, image_url
            except Exception as e:
                logger.error("create image error: {}".format(e))
                return False, "å›¾ç‰‡ç”Ÿæˆå¤±è´¥"
        elif text_to_image_model == "dall-e-3":
            api_version = conf().get("azure_api_version", "2024-02-15-preview")
            endpoint = conf().get("azure_openai_dalle_api_base","open_ai_api_base")
            # æ£€æŸ¥endpointæ˜¯å¦ä»¥/ç»“å°¾
            if not endpoint.endswith("/"):
                endpoint = endpoint + "/"
            url = "{}openai/deployments/{}/images/generations?api-version={}".format(endpoint, conf().get("azure_openai_dalle_deployment_id","text_to_image"),api_version)
            api_key = conf().get("azure_openai_dalle_api_key","open_ai_api_key")
            headers = {"api-key": api_key, "Content-Type": "application/json"}
            try:
                body = {"prompt": query, "size": conf().get("image_create_size", "1024x1024"), "quality": conf().get("dalle3_image_quality", "standard")}
                submission = requests.post(url, headers=headers, json=body)
                image_url = submission.json()['data'][0]['url']
                return True, image_url
            except Exception as e:
                logger.error("create image error: {}".format(e))
                return False, "å›¾ç‰‡ç”Ÿæˆå¤±è´¥"
        else:
            return False, "å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼Œæœªé…ç½®text_to_imageå‚æ•°"
